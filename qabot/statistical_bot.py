import os, requests
import json

import pandas as pd
import numpy as np
import streamlit as st

from datetime import datetime
from document_parser.document_upload import save_to_tmp_dir
from document_parser.excel_parser import get_topk_rows_from_file, detect_headers_llm
from tools.code_generator import code_generator_tool
from tools.code_executor import code_executor_tool

from utils.logging import get_logger
logger = get_logger("statistical_bot")

def filter_and_join(tup, sep='_'):
    # è¿‡æ»¤æ‰ 'Unnamed: x_level_y' å½¢å¼çš„å€¼
    filtered_tup = [item for item in tup if not str(item).startswith('Unnamed:')]
    # ç”¨è¿æ¥ç¬¦æ‹¼æ¥å‰©ä½™å…ƒç´ 
    return sep.join(filtered_tup)

st.title("AI åº”ç”¨æ¼”ç¤º")
st.write("ğŸ“‰ é—®æ•°")

user_input = st.chat_input(
    placeholder="è¯·ä¸Šä¼ æ–‡ä»¶å¹¶è¾“å…¥æ‚¨çš„é—®é¢˜...",
    # accept_file="multiple",
    accept_file=True,
    file_type=["xlsx", "xls", "csv"]
)
UPLOAD_DIR = os.getenv("TMP_DIR")
if user_input and user_input.text:
    st.markdown(user_input.text)
    uploaded_files = user_input.get("files", [])
    logger.info(f"user upload files: {uploaded_files}")
    if uploaded_files:
        with st.spinner("æ­£åœ¨ä¸Šä¼ æ–‡ä»¶..."):
            file_list = save_to_tmp_dir(uploaded_files)
        file_headers = {}
        df_info = {}
        with st.spinner("æ­£åœ¨è¯»å–æ–‡ä»¶..."):
            for f in file_list:
                df_info[f] = []
                data_sample = get_topk_rows_from_file(f"{f}")
                file_headers[f] = detect_headers_llm(data_sample)
                for k, v in file_headers[f].items():
                    # print(f"file name: {f}, key: {k}, value: {v}")
                    sheet_headers = v
                    if f.endswith(".xlsx") or f.endswith(".xls"):
                        df = pd.read_excel(f"{f}", sheet_name=k, header=v)
                        # print(df.columns)
                        # è·å–åˆ—å
                        columns = list(df.columns)
                        is_multiindex = False
                        if len(v) > 1:
                            # è½¬æ¢ä¸ºå­—ç¬¦ä¸²åˆ—è¡¨
                            columns = [filter_and_join(tup) for tup in columns]
                            is_multiindex = True
                        # if len(df) > 20:
                        df_info[f].append({
                            "sheet_name": k,
                            "header": v,
                            "multiindex": is_multiindex,
                            "column_info(merged)": columns,
                            "data_len": len(df)
                        })
                        # else :
                        #     df_info[f].append({
                        #         "sheet_name": k,
                        #         "header": v,
                        #         "multiindex": is_multiindex,
                        #         "column_info(merged)": columns,
                        #         "data_len": len(df),
                        #         "data": df.values.tolist()
                        #     })
                    elif f.endswith(".csv"):
                        df = pd.read_csv(f"{UPLOAD_DIR}/{f}")
                        # if len(df) > 20:
                        df_info[f].append({
                            "sheet_name": None,
                            "header": 0,
                            "multiindex": False,
                            "column_info(merged)": list(df.columns),
                            "data_len": len(df)
                        })
                        # else :
                        #     df_info[f].append({
                        #         "sheet_name": k,
                        #         "header": v,
                        #         "multiindex": is_multiindex,
                        #         "column_info(merged)": columns,
                        #         "data_len": len(df),
                        #         "data": df.values.tolist()
                        #     })
        with st.spinner("æ­£åœ¨åˆ†ææ–‡ä»¶..."):
            # è°ƒç”¨ LLM è¿›è¡Œè§£æ
            base_url = os.getenv("LLM_HOST")

            tools=[{
                "type": "function",
                "function":{
                    "name": "code_generator_tool",
                    "description": "æ ¹æ®ç”¨æˆ·é—®é¢˜ã€æ–‡ä»¶è·¯å¾„ã€æ–‡ä»¶ä¿¡æ¯å’Œæ¨¡å‹åç§°ç”Ÿæˆpythonä»£ç ",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "query": {
                                "type": "string",
                                "description": "ç”¨æˆ·é—®é¢˜"
                            },
                            "filepath": {
                                "type": "string",
                                "description": "æ–‡ä»¶è·¯å¾„"
                            },
                            "file_structure": {
                                "type": "object",
                                "description": "æ–‡ä»¶ä¿¡æ¯"
                            }
                        },
                        "required": ["query", "filepath", "file_structure"]
                    }
                }},{
                "type": "function",
                "function":{
                    "name": "code_executor_tool",
                    "description": "æ‰§è¡Œpythonä»£ç å¹¶è¿”å›ç»“æœ",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "code": {
                                "type": "string",
                                "description": "å¾…æ‰§è¡Œçš„pythonä»£ç "
                            }
                        },
                        "required": ["code"]
                    }
                }}
            ]

            sys_prompt = f"""
            ä½ æ˜¯ä¸€ä¸ª Excel æ•°æ®åˆ†æå¸ˆï¼Œæ ¹æ®ç”¨æˆ·æä¾›çš„ Excel æ–‡ä»¶å’Œæ–‡ä»¶ç»“æ„ä¿¡æ¯å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚ä½ éœ€è¦æ ¹æ®å·²çŸ¥æƒ…å†µåˆ¤æ–­æ˜¯å¦å¯ä»¥ç›´æ¥å›ç­”é—®é¢˜ï¼Œè‹¥ä¸èƒ½ç›´æ¥å›ç­”ï¼Œåˆ™ä½¿ç”¨æä¾›çš„å·¥å…·æ¥å¤„ç† Excel æ–‡ä»¶å¹¶å›ç­”é—®é¢˜ã€‚

            å¯ç”¨å·¥å…·åŠè°ƒç”¨æ–¹æ³•ï¼š
            1. code_generator_tool: 
                - æè¿°: ä½¿ç”¨æ­¤å·¥å…·æ ¹æ®ç”¨æˆ·é—®é¢˜ã€æ–‡ä»¶è·¯å¾„ã€æ–‡ä»¶ä¿¡æ¯ç”Ÿæˆ Python ä»£ç 
            2. code_executor_tool:
                - æè¿°: ä½¿ç”¨æ­¤å·¥å…·æ‰§è¡Œ Python ä»£ç 
            
            ä½†éœ€è¦è°ƒç”¨å·¥å…·æ—¶ï¼Œè¯·åŠ¡å¿…ç¡®ä¿è¿”å›çš„å·¥å…·å‚æ•°æ»¡è¶³JSONè§„èŒƒ
            """

            user_prompt = f"""
            ç”¨æˆ·é—®é¢˜: {user_input.text}
            Excelæ–‡ä»¶è·¯å¾„: {file_list}
            Excelæ–‡ä»¶ä¿¡æ¯: {df_info}
            """

            messages = [
                {"role":"system", "content": sys_prompt},{"role":"user", "content": user_prompt}
            ]
            data = {
                "model": "qwen2.5:latest",
                "messages": messages,
                "tools": tools,
                "temperature": 0.1
            }
            response = requests.post(f"{base_url}/v1/chat/completions", json=data)
            response_json = response.json()
            print(response_json)

            finish_reason = response_json['choices'][0]['finish_reason']
            if finish_reason == "stop":
                content = response_json['choices'][0]['message'].get('content', '')
                if "<tool_call>" in content:
                    start_index = content.find('<tool_call>\n')
                    end_index = content.find('\n</tool_call>')
                    logger.debug(f"tool call in content.\nstart_index: {start_index}, end_index: {end_index}")
                    if start_index != -1 and end_index != -1:
                        tool_call_str = content[start_index + len('<tool_call>'):end_index].strip().replace("True", "true").replace("False", "false")
                        logger.info(f"Extracted tool_call_str: {tool_call_str}")
                        try:
                            tool_call_json = json.loads(tool_call_str)
                            logger.info(f"Parsed tool_call name: {tool_call_json['name']}")
                            tool_name = tool_call_json['name']
                            tool_args = tool_call_json['arguments']
                            if isinstance(tool_args, str):
                                tool_args = json.loads(tool_args)
                            if tool_name == "code_generator_tool":
                                query = tool_args['query']
                                filepath = tool_args['filepath']
                                file_structure = tool_args['file_structure']
                                generated_code = code_generator_tool(query, filepath, file_structure)
                                print(f"Generated code: {generated_code}")

                                # è°ƒç”¨ code_executor_tool æ‰§è¡Œç”Ÿæˆçš„ä»£ç 
                                result = code_executor_tool(generated_code)
                                print(f"Execution result: {result}")

                                # æ„å»ºæ–°çš„æ¶ˆæ¯ï¼Œå°†æ‰§è¡Œç»“æœä¼ é€’ç»™å¤§æ¨¡å‹
                                new_user_prompt = f"ä»£ç æ‰§è¡Œç»“æœä¸º: {result}ã€‚è¯·æ ¹æ®è¿™ä¸ªç»“æœæ€»ç»“è¾“å‡ºã€‚"
                                new_messages = messages + [{"role": "assistant", "content": content}, {"role": "user", "content": new_user_prompt}]
                                new_data = {
                                    "model": "qwen2.5:latest",
                                    "messages": new_messages,
                                    "temperature": 0.3
                                }
                                new_response = requests.post(f"{base_url}/v1/chat/completions", json=new_data)
                                new_response_json = new_response.json()
                                summary = new_response_json['choices'][0]['message'].get('content', '')
                                logger.info(f"æ€»ç»“è¾“å‡º: {summary}")
                                st.markdown(summary)
                        except json.JSONDecodeError as e:
                            logger.error(f"Failed to parse tool_call_str as JSON: {tool_call_str}, error: {e}")
                    else:
                        logger.warning("Tool call tags found, but indices are invalid.")
                else: 
                    logger.info(f"answer directly: {content}")
                    st.markdown(content)
            elif finish_reason == "tool_calls":
                for tool_call in response_json['choices'][0]['message']['tool_calls']:                        
                    tool_name = tool_call['function']['name']
                    tool_args = tool_call['function']['arguments']
                    try: 
                        tool_args = json.loads(tool_args)
                        print(f"tool_args: {tool_args}")
                        if tool_name == "code_generator_tool":
                            query = tool_args['query']
                            filepath = tool_args['filepath']
                            file_structure = tool_args['file_structure']
                            generated_code = code_generator_tool(query, filepath, file_structure)
                            print(f"Generated code: {generated_code}")

                            # è°ƒç”¨ code_executor_tool æ‰§è¡Œç”Ÿæˆçš„ä»£ç 
                            result = code_executor_tool(generated_code)
                            print(f"Execution result: {result}")

                            # æ„å»ºæ–°çš„æ¶ˆæ¯ï¼Œå°†æ‰§è¡Œç»“æœä¼ é€’ç»™å¤§æ¨¡å‹
                            new_user_prompt = f"ä»£ç æ‰§è¡Œç»“æœä¸º: {result}ã€‚è¯·æ ¹æ®è¿™ä¸ªç»“æœæ€»ç»“è¾“å‡ºã€‚"
                            new_messages = messages + [{"role": "assistant", "content": response_json['choices'][0]['message']['content']}, {"role": "user", "content": new_user_prompt}]
                            new_data = {
                                "model": "qwen2.5:latest",
                                "messages": new_messages,
                                "temperature": 0.3
                            }
                            new_response = requests.post(f"{base_url}/v1/chat/completions", json=new_data)
                            new_response_json = new_response.json()
                            summary = new_response_json['choices'][0]['message'].get('content', '')
                            print(f"æ€»ç»“è¾“å‡º: {summary}")
                            st.markdown(summary)


                    except json.JSONDecodeError:
                        print("è§£æ tool_call çš„ JSON æ•°æ®æ—¶å‡ºé”™ï¼Œè¯·æ£€æŸ¥æ ¼å¼ã€‚")
